{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JtJ2IiF_D_TB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtJ2IiF_D_TB",
        "outputId": "d8035512-c9b8-4477-828b-0ebde6dda79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38",
      "metadata": {
        "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU, LSTM, Dense, Bidirectional, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4",
      "metadata": {
        "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4"
      },
      "outputs": [],
      "source": [
        "# getting our text file\n",
        "with open('/content/1661-0.txt') as f:\n",
        "    data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b37da10-c72c-49a6-83b3-91ed9504689d",
      "metadata": {
        "id": "5b37da10-c72c-49a6-83b3-91ed9504689d"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer() # Create a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_W2hlti-J-jD",
      "metadata": {
        "id": "_W2hlti-J-jD"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49S4gpOJHzHl",
      "metadata": {
        "id": "49S4gpOJHzHl"
      },
      "outputs": [],
      "source": [
        "# Save the tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa",
      "metadata": {
        "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62244c2-b237-46e0-b53e-3d059409d02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of words =  8931\n"
          ]
        }
      ],
      "source": [
        "keys_list = tokenizer.word_index  ## creates a word to index mapping\n",
        "print(\"No. of words = \" , len(keys_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b351bd43-00b3-4421-b572-b633849b382c",
      "metadata": {
        "id": "b351bd43-00b3-4421-b572-b633849b382c"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "\n",
        "for sentence in data.split('\\n'):\n",
        "\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]  ## the [0] index is putting all sequences in one list\n",
        "    for i in range( 1, len(tokenized_sentence)):\n",
        "        input_sequences.append(tokenized_sentence[:i+1]) ## apppendind tokenized sentences to input_sequences list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb",
      "metadata": {
        "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb"
      },
      "outputs": [],
      "source": [
        "## length of the biggest line\n",
        "max_len = max(len(x) for x in input_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa",
      "metadata": {
        "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_input_sequences = pad_sequences(input_sequences, ## vector who's vector we need to padd\n",
        "                                       maxlen=max_len,  ## length of sequence's vectors\n",
        "                                       padding='pre'    ## padding from the starting\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758caffb-288e-4c16-878d-f969fde3d081",
      "metadata": {
        "id": "758caffb-288e-4c16-878d-f969fde3d081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12550db7-b2a5-46b8-c4f1-309521bf8a12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,  145, 4790],\n",
              "       [   0,    0,    0, ...,  145, 4790,    1],\n",
              "       [   0,    0,    0, ..., 4790,    1, 1020],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    3,  360,   83],\n",
              "       [   0,    0,    0, ...,  360,   83,  358],\n",
              "       [   0,    0,    0, ...,   83,  358, 1673]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89102ca3-b2fe-4a34-97c2-666164405ae8",
      "metadata": {
        "id": "89102ca3-b2fe-4a34-97c2-666164405ae8"
      },
      "outputs": [],
      "source": [
        "## X will contain all elements instead of last one in list\n",
        "X = padded_input_sequences[:,:-1]\n",
        "\n",
        "## y will only contain last element of list\n",
        "y = padded_input_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
      "metadata": {
        "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a97bd8-5027-4c0a-ef80-152a4db51ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((101619, 19), (101619,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be143d5-2869-4676-b347-eb09da09a821",
      "metadata": {
        "id": "9be143d5-2869-4676-b347-eb09da09a821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9760c9-030f-4553-8f6b-363109cc4c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Total number of word:  8931\n"
          ]
        }
      ],
      "source": [
        "print(\" Total number of word: \" ,len(tokenizer.word_index))\n",
        "\n",
        "INPUT_LENGTH = len(tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab",
      "metadata": {
        "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=INPUT_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed",
      "metadata": {
        "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845b4c23-f59c-4eca-928a-afdc6e747f2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101619, 8932)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf",
      "metadata": {
        "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(INPUT_LENGTH, 100))\n",
        "model.add(Bidirectional(GRU(units=80, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(GRU(units=80, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(GRU(units=80)))\n",
        "model.add(Dense(INPUT_LENGTH, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab",
      "metadata": {
        "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
      "metadata": {
        "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "402947c5-1de8-464a-b35d-941145f56511"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d8a2cb-90cc-4698-8418-76ec38384450",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30d8a2cb-90cc-4698-8418-76ec38384450",
        "outputId": "382f383a-cedd-4135-f18b-daae16a437ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 16ms/step - accuracy: 0.0611 - loss: 6.5585\n",
            "Epoch 2/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 17ms/step - accuracy: 0.1110 - loss: 5.5886\n",
            "Epoch 3/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 19ms/step - accuracy: 0.1356 - loss: 5.2272\n",
            "Epoch 4/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 16ms/step - accuracy: 0.1478 - loss: 5.0077\n",
            "Epoch 5/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.1613 - loss: 4.7754\n",
            "Epoch 6/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.1704 - loss: 4.5998\n",
            "Epoch 7/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 16ms/step - accuracy: 0.1821 - loss: 4.4218\n",
            "Epoch 8/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.1919 - loss: 4.2712\n",
            "Epoch 9/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.2017 - loss: 4.1252\n",
            "Epoch 10/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.2139 - loss: 3.9872\n",
            "Epoch 11/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.2252 - loss: 3.8660\n",
            "Epoch 12/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.2367 - loss: 3.7463\n",
            "Epoch 13/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.2434 - loss: 3.6569\n",
            "Epoch 14/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.2584 - loss: 3.5550\n",
            "Epoch 15/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.2694 - loss: 3.4627\n",
            "Epoch 16/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.2808 - loss: 3.3738\n",
            "Epoch 17/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 16ms/step - accuracy: 0.2893 - loss: 3.3135\n",
            "Epoch 18/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.2957 - loss: 3.2498\n",
            "Epoch 19/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.3068 - loss: 3.1852\n",
            "Epoch 20/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.3139 - loss: 3.1242\n",
            "Epoch 21/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3231 - loss: 3.0795\n",
            "Epoch 22/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3330 - loss: 3.0189\n",
            "Epoch 23/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.3405 - loss: 2.9691\n",
            "Epoch 24/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 17ms/step - accuracy: 0.3453 - loss: 2.9173\n",
            "Epoch 25/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 16ms/step - accuracy: 0.3593 - loss: 2.8561\n",
            "Epoch 26/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3599 - loss: 2.8420\n",
            "Epoch 27/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3695 - loss: 2.7746\n",
            "Epoch 28/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3744 - loss: 2.7603\n",
            "Epoch 29/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3802 - loss: 2.7210\n",
            "Epoch 30/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3864 - loss: 2.6829\n",
            "Epoch 31/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.3947 - loss: 2.6402\n",
            "Epoch 32/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.3976 - loss: 2.6204\n",
            "Epoch 33/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4028 - loss: 2.5939\n",
            "Epoch 34/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 16ms/step - accuracy: 0.4080 - loss: 2.5664\n",
            "Epoch 35/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.4104 - loss: 2.5424\n",
            "Epoch 36/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4160 - loss: 2.5102\n",
            "Epoch 37/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4248 - loss: 2.4697\n",
            "Epoch 38/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.4299 - loss: 2.4465\n",
            "Epoch 39/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.4282 - loss: 2.4379\n",
            "Epoch 40/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 16ms/step - accuracy: 0.4351 - loss: 2.4054\n",
            "Epoch 41/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4399 - loss: 2.3776\n",
            "Epoch 42/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4423 - loss: 2.3719\n",
            "Epoch 43/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4477 - loss: 2.3431\n",
            "Epoch 44/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4477 - loss: 2.3303\n",
            "Epoch 45/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4588 - loss: 2.2966\n",
            "Epoch 46/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4589 - loss: 2.2803\n",
            "Epoch 47/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4588 - loss: 2.2634\n",
            "Epoch 48/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4666 - loss: 2.2333\n",
            "Epoch 49/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4724 - loss: 2.2099\n",
            "Epoch 50/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4740 - loss: 2.1978\n",
            "Epoch 51/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4761 - loss: 2.1862\n",
            "Epoch 52/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4813 - loss: 2.1581\n",
            "Epoch 53/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4825 - loss: 2.1602\n",
            "Epoch 54/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.4854 - loss: 2.1242\n",
            "Epoch 55/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4932 - loss: 2.1083\n",
            "Epoch 56/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 16ms/step - accuracy: 0.4924 - loss: 2.1042\n",
            "Epoch 57/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.4961 - loss: 2.0899\n",
            "Epoch 58/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.5012 - loss: 2.0761\n",
            "Epoch 59/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 17ms/step - accuracy: 0.5028 - loss: 2.0535\n",
            "Epoch 60/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.5039 - loss: 2.0379\n",
            "Epoch 61/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 19ms/step - accuracy: 0.5092 - loss: 2.0243\n",
            "Epoch 62/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.5103 - loss: 2.0180\n",
            "Epoch 63/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 16ms/step - accuracy: 0.5147 - loss: 1.9853\n",
            "Epoch 64/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 16ms/step - accuracy: 0.5171 - loss: 1.9821\n",
            "Epoch 65/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5177 - loss: 1.9704\n",
            "Epoch 66/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5207 - loss: 1.9565\n",
            "Epoch 67/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5224 - loss: 1.9489\n",
            "Epoch 68/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.5243 - loss: 1.9395\n",
            "Epoch 69/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.5282 - loss: 1.9243\n",
            "Epoch 70/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5309 - loss: 1.9091\n",
            "Epoch 71/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.5320 - loss: 1.9045\n",
            "Epoch 72/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5355 - loss: 1.8942\n",
            "Epoch 73/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.5382 - loss: 1.8772\n",
            "Epoch 74/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.5411 - loss: 1.8736\n",
            "Epoch 75/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 17ms/step - accuracy: 0.5429 - loss: 1.8568\n",
            "Epoch 76/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.5460 - loss: 1.8410\n",
            "Epoch 77/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5488 - loss: 1.8315\n",
            "Epoch 78/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5445 - loss: 1.8451\n",
            "Epoch 79/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 16ms/step - accuracy: 0.5517 - loss: 1.8098\n",
            "Epoch 80/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5511 - loss: 1.8107\n",
            "Epoch 81/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.5529 - loss: 1.8009\n",
            "Epoch 82/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5570 - loss: 1.7871\n",
            "Epoch 83/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 16ms/step - accuracy: 0.5601 - loss: 1.7733\n",
            "Epoch 84/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.5624 - loss: 1.7672\n",
            "Epoch 85/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 17ms/step - accuracy: 0.5657 - loss: 1.7535\n",
            "Epoch 86/100\n",
            "\u001b[1m2564/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.5657 - loss: 1.7427"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 86\n",
        "\n",
        "history = model.fit(X, y, epochs=N_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dq3FNKrWMlRN",
      "metadata": {
        "id": "Dq3FNKrWMlRN"
      },
      "outputs": [],
      "source": [
        "model.save('next_word_prediction.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}